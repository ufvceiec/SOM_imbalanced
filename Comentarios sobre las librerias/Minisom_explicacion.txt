-------------------------------------------------------------------
						LIBRERÍA MINISOM
-------------------------------------------------------------------

En este archivo se explica de forma básica el uso de la librería Minisom (https://github.com/JustGlowing/minisom)
(Para comprobar cada función de la librería en concreto -> https://github.com/JustGlowing/minisom/blob/master/minisom.py)

Uso básico, crear y entrenar:

# Importar la librería --> from minisom import MiniSom 
# Initialization of 6x6 SOM --> som = MiniSom(6, 6, 4, sigma=0.3, learning_rate=0.5)
# Trains the SOM with 100 iterations --> som.train(data, 100) 



-------------------------------------------------------------------

Vamos con la función de creación del SOM

Parámetros posibles de entrada para la creación del SOM:
Minisom(self, x, y, input_len, sigma=1.0, learning_rate=0.5,decay_function=asymptotic_decay,
neighborhood_function='gaussian', topology='rectangular',activation_distance='euclidean', random_seed=None)

Donde:
----------
        x : int
            x dimension of the SOM.

        y : int
            y dimension of the SOM.

        input_len : int
            Number of the elements of the vectors in input. (La dimensionalidad de los datos de entrada)

        sigma : float, optional (default=1.0)
            Spread of the neighborhood function, needs to be adequate
            to the dimensions of the map.
            (at the iteration t we have sigma(t) = sigma / (1 + t/T)
            where T is #num_iteration/2)

        learning_rate : initial learning rate
            (at the iteration t we have
            learning_rate(t) = learning_rate / (1 + t/T)
            where T is #num_iteration/2)

        decay_function : function (default=asymptotic_decay)
            Function that reduces learning_rate and sigma at each iteration
            the default function is:
                        learning_rate / (1+t/(max_iterarations/2))
            A custom decay function will need to to take in input
            three parameters in the following order:
            1. learning rate
            2. current iteration
            3. maximum number of iterations allowed
            Note that if a lambda function is used to define the decay
            MiniSom will not be pickable anymore.

        neighborhood_function : string, optional (default='gaussian')
            Function that weights the neighborhood of a position in the map.
            Possible values: 'gaussian', 'mexican_hat', 'bubble', 'triangle'

        topology : string, optional (default='rectangular')
            Topology of the map.
            Possible values: 'rectangular', 'hexagonal'

        activation_distance : string, callable optional (default='euclidean')
            Distance used to activate the map.
            Possible values: 'euclidean', 'cosine', 'manhattan', 'chebyshev'
            Example of callable that can be passed:
            def euclidean(x, w):
                return linalg.norm(subtract(x, w), axis=-1)

        random_seed : int, optional (default=None)
            Random seed to use.
"""
-------------------------------------------------------------------
-------------------------------------------------------------------



FUNCIONES ÚTILES:
-------------------------------------------------------------------
Función para entrenar el SOM:

def train(self, data, num_iteration,
              random_order=False, verbose=False, use_epochs=False):
        """Trains the SOM.
        Parameters
        ----------
        data : np.array or list
            Data matrix.
        num_iteration : int
            If use_epochs is False, the weights will be
            updated num_iteration times. Otherwise they will be updated
            len(data)*num_iteration times.
        random_order : bool (default=False)
            If True, samples are picked in random order.
            Otherwise the samples are picked sequentially.
        verbose : bool (default=False)
            If True the status of the training will be
            printed each time the weights are updated.
        use_epochs : bool (default=False)
            If True the SOM will be trained for num_iteration epochs.
            In one epoch the weights are updated len(data) times and
            the learning rate is constat throughout a single epoch.
        """
-------------------------------------------------------------------

-------------------------------------------------------------------
Función para obtener el error de cuantificación, error que indica la distancia entre
un patrón de entrada y la neurona ganadora. En este caso devuelve el promedio de ese
error en todo el conjunto de datos.

def quantization_error(self, data):
        """Returns the quantization error computed as the average
        distance between each input sample and its best matching unit."""
        self._check_input_len(data)
        return norm(data-self.quantization(data), axis=1).mean()
-------------------------------------------------------------------

-------------------------------------------------------------------
Función para obtener el error topológico, en este caso el error topológico es cero
para un patrón de entrada si la neurona ganadora y la segunda ganadora son adyacentes,
en caso contrario es 1. El error topológico devuelve el promedio de este error en todo
el conjunto de datos.

def topographic_error(self, data):
        """Returns the topographic error computed by finding
        the best-matching and second-best-matching neuron in the map
        for each input and then evaluating the positions.
        A sample for which these two nodes are not adjacent counts as
        an error. The topographic error is given by the
        the total number of errors divided by the total of samples.
        If the topographic error is 0, no error occurred.
        If 1, the topology was not preserved for any of the samples."""
-------------------------------------------------------------------

